{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the necessary requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/rakeshpolepeddi/Library/Python/3.9/lib/python/site-packages (from nltk) (2023.6.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rakeshpolepeddi/Library/Python/3.9/lib/python/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/rakeshpolepeddi/Library/Python/3.9/lib/python/site-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi==0.85.1->chromadb==0.3.27) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: six>=1.10.0 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from lomond->ibm-watson-machine-learning>=1.0.312) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk | tail -n 1\n",
    "!pip install sentence_transformers | tail -n 1\n",
    "!pip install chromadb==0.3.27 | tail -n 1\n",
    "!pip install \"ibm-watson-machine-learning>=1.0.312\" | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.6'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the data and initializing the model related params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rakeshpolepeddi/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>RHBA-2011:1656: mod_nss bug fix update  (None)</td>\n",
       "      <td>The mod_nss module provides strong cryptograph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RHBA-2012:0763: glibc bug fix and enhancement ...</td>\n",
       "      <td>The glibc packages provide the standard C and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RHBA-2012:0881: freeradius bug fix and enhance...</td>\n",
       "      <td>FreeRADIUS is an open-source Remote Authentica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RHBA-2013:0363: sudo bug fix and enhancement u...</td>\n",
       "      <td>The sudo (super user do) utility allows system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RHBA-2013:0386: tuned bug fix update (None)</td>\n",
       "      <td>The tuned packages contain a daemon that tunes...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              title  \\\n",
       "0   0     RHBA-2011:1656: mod_nss bug fix update  (None)   \n",
       "1   1  RHBA-2012:0763: glibc bug fix and enhancement ...   \n",
       "2   2  RHBA-2012:0881: freeradius bug fix and enhance...   \n",
       "3   3  RHBA-2013:0363: sudo bug fix and enhancement u...   \n",
       "4   4        RHBA-2013:0386: tuned bug fix update (None)   \n",
       "\n",
       "                                         description  \n",
       "0  The mod_nss module provides strong cryptograph...  \n",
       "1  The glibc packages provide the standard C and ...  \n",
       "2  FreeRADIUS is an open-source Remote Authentica...  \n",
       "3  The sudo (super user do) utility allows system...  \n",
       "4  The tuned packages contain a daemon that tunes...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "#from botocore.client import Config\n",
    "#import ibm_boto3\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.api.types import EmbeddingFunction\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# Adding the default params to the models \n",
    "\n",
    "api_key = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "project_id = 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "\n",
    "model_credentials = {\n",
    "    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "    \"apikey\": 'XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX'\n",
    "}\n",
    "\n",
    "\n",
    "'''cos_client = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id= api_key,\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3.private.us-south.cloud-object-storage.appdomain.cloud')\n",
    "\n",
    "bucket = 'watsonxchallengesandbox-donotdelete-pr-hdmgfjqdjzh8c0'\n",
    "'''\n",
    "object_key = 'vulnerability.csv'\n",
    "object_key = 'Vulners-3000.xlsx'\n",
    "\n",
    "\n",
    "'''body = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "'''\n",
    "\n",
    "df = pd.read_excel(object_key)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>866.458404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>750.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID\n",
       "count  3001.000000\n",
       "mean   1500.000000\n",
       "std     866.458404\n",
       "min       0.000000\n",
       "25%     750.000000\n",
       "50%    1500.000000\n",
       "75%    2250.000000\n",
       "max    3000.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an embedding function\n",
    "\n",
    "Note that you can feed a custom embedding function to be used by chromadb. The performance of chromadb may differ depending on the embedding model used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniLML6V2EmbeddingFunction(EmbeddingFunction):\n",
    "    MODEL = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    def __call__(self, texts):\n",
    "        return MiniLML6V2EmbeddingFunction.MODEL.encode(texts).tolist()\n",
    "emb_func = MiniLML6V2EmbeddingFunction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Chroma upsert\n",
    "\n",
    "Upserting a document means update the document even if it exists in the database. Otherwise re-inserting a document throws an error. This is useful for experimentation purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"data\"\n",
    "knowledge_base_dir = f\"{data_root}/knowledge_base\"\n",
    "class ChromaWithUpsert:\n",
    "    def __init__(\n",
    "            self,\n",
    "            name = \"watsonx_rag_collection\",\n",
    "            persist_directory=knowledge_base_dir,\n",
    "            embedding_function=None,\n",
    "            collection_metadata = None,\n",
    "    ):\n",
    "        self._client_settings = chromadb.config.Settings()\n",
    "        if persist_directory is not None:\n",
    "            self._client_settings = chromadb.config.Settings(\n",
    "                chroma_db_impl=\"duckdb+parquet\",\n",
    "                persist_directory=persist_directory,\n",
    "            )\n",
    "        self._client = chromadb.Client(self._client_settings)\n",
    "        self._embedding_function = embedding_function\n",
    "        self._persist_directory = persist_directory\n",
    "        self._name = name\n",
    "        self._collection = self._client.get_or_create_collection(\n",
    "            name=self._name,\n",
    "            embedding_function=self._embedding_function\n",
    "            if self._embedding_function is not None\n",
    "            else None,\n",
    "            metadata=collection_metadata,\n",
    "        )\n",
    "\n",
    "    def upsert_texts(\n",
    "        self,\n",
    "        texts,\n",
    "        metadata = None,\n",
    "        ids = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"Run more texts through the embeddings and add to the vectorstore.\n",
    "        Args:\n",
    "            :param texts (Iterable[str]): Texts to add to the vectorstore.\n",
    "            :param metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
    "            :param ids (Optional[List[str]], optional): Optional list of IDs.\n",
    "            :param metadata: Optional[List[dict]] - optional metadata (such as title, etc.)\n",
    "        Returns:\n",
    "            List[str]: List of IDs of the added texts.\n",
    "        \"\"\"\n",
    "        # TODO: Handle the case where the user doesn't provide ids on the Collection\n",
    "        if ids is None:\n",
    "            import uuid\n",
    "            ids = [str(uuid.uuid4()) for _ in range(0, len(texts))]\n",
    "        embeddings = None\n",
    "        self._collection.upsert(\n",
    "            metadatas=metadata, documents=texts, ids=ids\n",
    "        )\n",
    "        return ids\n",
    "\n",
    "    def is_empty(self):\n",
    "        return self._collection.count()==0\n",
    "\n",
    "    def persist(self):\n",
    "        self._client.persist()\n",
    "\n",
    "    def query(self, query_texts:str, n_results:int=5):\n",
    "        \"\"\"\n",
    "        Returns the closests vector to the question vector\n",
    "        :param query_texts: the question\n",
    "        :param n_results: number of results to generate\n",
    "        :return: the closest result to the given question\n",
    "        \"\"\"\n",
    "        return self._collection.query(query_texts=query_texts, n_results=n_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed and index documents with Chroma\n",
    "\n",
    "**Note: Could take several minutes if you don't have pre-built indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "CPU times: user 2min 33s, sys: 29.2 s, total: 3min 2s\n",
      "Wall time: 46.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df['indextext'] = df['title'].astype(str) + \"\\n\" + df['description']\n",
    "\n",
    "\n",
    "\n",
    "chroma = ChromaWithUpsert(\n",
    "    name=f\"nq910_minilm6v2\",\n",
    "    embedding_function=emb_func,  # you can have something here using /embed endpoint\n",
    "    persist_directory=knowledge_base_dir,\n",
    ")\n",
    "print(chroma.is_empty())\n",
    "if chroma.is_empty():\n",
    "    _ = chroma.upsert_texts(\n",
    "        texts=df.indextext.tolist(),\n",
    "        metadata=[{'title': title} for title in df.title], ids=None,)\n",
    "    chroma.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ask question based on embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma = ChromaWithUpsert(\n",
    "    name=f\"nq910_minilm6v2\",\n",
    "    embedding_function=emb_func,  # you can have something here using /embed endpoint\n",
    "    persist_directory=knowledge_base_dir,\n",
    ")\n",
    "\n",
    "\n",
    "relevant_contexts = []\n",
    "question_texts = ['Is mod_nss safe to use?']\n",
    "for question_text in question_texts:\n",
    "    relevant_chunks = chroma.query(\n",
    "        query_texts=[question_text],\n",
    "        n_results=2,\n",
    "    )\n",
    "    relevant_contexts.append(relevant_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the set of chunks for one of the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========\n",
      "Paragraph index :  f155b938-bc59-4498-9817-aceda4b28fcb\n",
      "Paragraph :  RHSA-2016:2602: mod_nss security, bug fix, and enhancement update (Low)\n",
      "The mod_nss module provides strong cryptography for the Apache HTTP Server via the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols, using the Network Security Services (NSS) security library.\n",
      "\n",
      "The following packages have been upgraded to a newer upstream version: mod_nss (1.0.14). (BZ#1299063)\n",
      "\n",
      "Security Fix(es):\n",
      "\n",
      "* A flaw was found in the way mod_nss parsed certain OpenSSL-style cipher strings. As a result, mod_nss could potentially use ciphers that were not intended to be enabled. (CVE-2016-3099)\n",
      "\n",
      "This issue was discovered by Rob Crittenden (Red Hat).\n",
      "\n",
      "Additional Changes:\n",
      "\n",
      "For detailed information on changes in this release, see the Red Hat Enterprise Linux 7.3 Release Notes linked from the References section.\n",
      "Distance :  0.9599862694740295\n",
      "=========\n",
      "Paragraph index :  ef77c233-1054-46d1-8358-94c0aa3bd665\n",
      "Paragraph :  RHSA-2013:1779: mod_nss security update (Moderate)\n",
      "The mod_nss module provides strong cryptography for the Apache HTTP Server\n",
      "via the Secure Sockets Layer (SSL) and Transport Layer Security (TLS)\n",
      "protocols, using the Network Security Services (NSS) security library.\n",
      "\n",
      "A flaw was found in the way mod_nss handled the NSSVerifyClient setting for\n",
      "the per-directory context. When configured to not require a client\n",
      "certificate for the initial connection and only require it for a specific\n",
      "directory, mod_nss failed to enforce this requirement and allowed a client\n",
      "to access the directory when no valid client certificate was provided.\n",
      "(CVE-2013-4566)\n",
      "\n",
      "Red Hat would like to thank Albert Smith of OUSD(AT&L) for reporting this\n",
      "issue.\n",
      "\n",
      "All mod_nss users should upgrade to this updated package, which contains a\n",
      "backported patch to correct this issue. The httpd service must be restarted\n",
      "for this update to take effect.\n",
      "Distance :  0.963577926158905\n"
     ]
    }
   ],
   "source": [
    "sample_chunks = relevant_contexts[0]\n",
    "for i, chunk in enumerate(sample_chunks['documents'][0]):\n",
    "    print(\"=========\")\n",
    "    print(\"Paragraph index : \", sample_chunks['ids'][0][i])\n",
    "    print(\"Paragraph : \", chunk)\n",
    "    print(\"Distance : \", sample_chunks['distances'][0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please answer the following.\n",
      "RHSA-2016:2602: mod_nss security, bug fix, and enhancement update (Low)\n",
      "The mod_nss module provides strong cryptography for the Apache HTTP Server via the Secure Sockets Layer (SSL) and Transport Layer Security (TLS) protocols, using the Network Security Services (NSS) security library.\n",
      "\n",
      "The following packages have been upgraded to a newer upstream version: mod_nss (1.0.14). (BZ#1299063)\n",
      "\n",
      "Security Fix(es):\n",
      "\n",
      "* A flaw was found in the way mod_nss parsed certain OpenSSL-style cipher strings. As a result, mod_nss could potentially use ciphers that were not intended to be enabled. (CVE-2016-3099)\n",
      "\n",
      "This issue was discovered by Rob Crittenden (Red Hat).\n",
      "\n",
      "Additional Changes:\n",
      "\n",
      "For detailed information on changes in this release, see the Red Hat Enterprise Linux 7.3 Release Notes linked from the References section.\n",
      "\n",
      "\n",
      "RHSA-2013:1779: mod_nss security update (Moderate)\n",
      "The mod_nss module provides strong cryptography for the Apache HTTP Server\n",
      "via the Secure Sockets Layer (SSL) and Transport Layer Security (TLS)\n",
      "protocols, using the Network Security Services (NSS) security library.\n",
      "\n",
      "A flaw was found in the way mod_nss handled the NSSVerifyClient setting for\n",
      "the per-directory context. When configured to not require a client\n",
      "certificate for the initial connection and only require it for a specific\n",
      "directory, mod_nss failed to enforce this requirement and allowed a client\n",
      "to access the directory when no valid client certificate was provided.\n",
      "(CVE-2013-4566)\n",
      "\n",
      "Red Hat would like to thank Albert Smith of OUSD(AT&L) for reporting this\n",
      "issue.\n",
      "\n",
      "All mod_nss users should upgrade to this updated package, which contains a\n",
      "backported patch to correct this issue. The httpd service must be restarted\n",
      "for this update to take effect.:\n",
      "\n",
      "Is mod_nss safe to use?\n"
     ]
    }
   ],
   "source": [
    "def make_prompt(context, question_text):\n",
    "    return (f\"Please answer the following.\\n\"\n",
    "          + f\"{context}:\\n\\n\"\n",
    "          + f\"{question_text}\")\n",
    "\n",
    "prompt_texts = []\n",
    "\n",
    "for relevant_context, question_text in zip(relevant_contexts, question_texts):\n",
    "    context = \"\\n\\n\\n\".join(relevant_context[\"documents\"][0])\n",
    "    prompt_text = make_prompt(context, question_text)\n",
    "    prompt_texts.append(prompt_text)\n",
    "\n",
    "print(prompt_texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the model params here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = ModelTypes.FLAN_UL2\n",
    "\n",
    "def create_model(params):\n",
    "    return Model(model_id=model_id, params=parameters, credentials=model_credentials, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no, mod_nss could potentially use ciphers that were not intended to be enabled. (CVE-2016-3099) This issue was discovered by Rob Crittenden (Red Hat). Additional Changes: For detailed information on changes in this release, see the Red Hat Enterprise Linux 7.3 Release Notes linked from the References section.']\n"
     ]
    }
   ],
   "source": [
    "from ibm_watson_machine_learning.foundation_models.utils.enums import DecodingMethods\n",
    "parameters = {\n",
    "    GenParams.DECODING_METHOD: DecodingMethods.GREEDY,\n",
    "    GenParams.MIN_NEW_TOKENS: 50,\n",
    "    GenParams.MAX_NEW_TOKENS: 100\n",
    "}\n",
    "model = create_model(parameters)\n",
    "results = []\n",
    "\n",
    "for prompt_text in prompt_texts:\n",
    "    results.append(model.generate_text(prompt=prompt_text))\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create and generate data from prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompts(comments, instruction=None):\n",
    "    parameters = {\n",
    "        GenParams.MAX_NEW_TOKENS: 100\n",
    "    }\n",
    "    model = create_model(params)\n",
    "    results = []\n",
    "    for input_text in comments:\n",
    "        results.append({'Q': input_text, 'A': model.generate_text(prompt=\" \".join([instruction, input_text] if instruction else [input_text]))})\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: what is the need to update java\n",
      "A: java is a general purpose programming language\n",
      "Q: Is there any open vulnerability in java\n",
      "A: java.security.getpass.invalidate()\n",
      "Q: Is there any fix for vulnerability in java 1.7\n",
      "A: Java 1.7.25 is the latest update.\n"
     ]
    }
   ],
   "source": [
    "comments = ['what is the need to update java', 'Is there any open vulnerability in java', 'Is there any fix for vulnerability in java 1.7']\n",
    "instruction = '''\n",
    "\n",
    "Title: RHSA-2013:0751: java-1.7.0-openjdk security update (Critical)\n",
    "\n",
    "packages provide the OpenJDK 7 Java Runtime Environment and the\n",
    "OpenJDK 7 Software Development Kit.\n",
    "\n",
    "Multiple flaws were discovered in the font layout engine in the 2D\n",
    "component. An untrusted Java application or applet could possibly use these\n",
    "flaws to trigger Java Virtual Machine memory corruption. (CVE-2013-1569,\n",
    "CVE-2013-2383, CVE-2013-2384)\n",
    "\n",
    "Multiple improper permission check issues were discovered in the Beans,\n",
    "Libraries, JAXP, and RMI components in OpenJDK. An untrusted Java\n",
    "application or applet could use these flaws to bypass Java sandbox\n",
    "restrictions. (CVE-2013-1558, CVE-2013-2422, CVE-2013-2436, CVE-2013-1518,\n",
    "CVE-2013-1557)\n",
    "\n",
    "The previous default value of the java.rmi.server.useCodebaseOnly property\n",
    "permitted the RMI implementation to automatically load classes from\n",
    "remotely specified locations. An attacker able to connect to an application\n",
    "using RMI could use this flaw to make the application execute arbitrary\n",
    "code. (CVE-2013-1537)\n",
    "\n",
    "Note: The fix for CVE-2013-1537 changes the default value of the property\n",
    "to true, restricting class loading to the local CLASSPATH and locations\n",
    "specified in the java.rmi.server.codebase property. Refer to Red Hat\n",
    "Bugzilla bug 952387 for additional details.\n",
    "\n",
    "The 2D component did not properly process certain images. An untrusted Java\n",
    "application or applet could possibly use this flaw to trigger Java Virtual\n",
    "Machine memory corruption. (CVE-2013-2420)\n",
    "\n",
    "It was discovered that the Hotspot component did not properly handle\n",
    "certain intrinsic frames, and did not correctly perform access checks and\n",
    "MethodHandle lookups. An untrusted Java application or applet could\n",
    "use these flaws to bypass Java sandbox restrictions. (CVE-2013-2431,\n",
    "CVE-2013-2421, CVE-2013-2423)\n",
    "\n",
    "It was discovered that JPEGImageReader and JPEGImageWriter in the ImageIO\n",
    "component did not protect against modification of their state while\n",
    "performing certain native code operations. An untrusted Java application or\n",
    "applet could possibly use these flaws to trigger Java Virtual Machine\n",
    "memory corruption. (CVE-2013-2429, CVE-2013-2430)\n",
    "\n",
    "The JDBC driver manager could incorrectly call the toString() method in\n",
    "JDBC drivers, and the ConcurrentHashMap class could incorrectly call the\n",
    "defaultReadObject() method. An untrusted Java application or applet could\n",
    "possibly use these flaws to bypass Java sandbox restrictions.\n",
    "(CVE-2013-1488, CVE-2013-2426)\n",
    "\n",
    "The sun.awt.datatransfer.ClassLoaderObjectInputStream class may incorrectly\n",
    "invoke the system class loader. An untrusted Java application or applet\n",
    "could possibly use this flaw to bypass certain Java sandbox restrictions.\n",
    "(CVE-2013-0401)\n",
    "\n",
    "Flaws were discovered in the Network component's InetAddress serialization,\n",
    "and the 2D component's font handling. An untrusted Java application or\n",
    "applet could possibly use these flaws to crash the Java Virtual Machine.\n",
    "(CVE-2013-2417, CVE-2013-2419)\n",
    "\n",
    "The MBeanInstantiator class implementation in the OpenJDK JMX component did\n",
    "not properly check class access before creating new instances. An untrusted\n",
    "Java application or applet could use this flaw to create instances of\n",
    "non-public classes. (CVE-2013-2424)\n",
    "\n",
    "It was discovered that JAX-WS could possibly create temporary files with\n",
    "insecure permissions. A local attacker could use this flaw to access\n",
    "temporary files created by an application using JAX-WS. (CVE-2013-2415)\n",
    "\n",
    "Note: If the web browser plug-in provided by the icedtea-web package was\n",
    "installed, the issues exposed via Java applets could have been exploited\n",
    "without user interaction if a user visited a malicious website.\n",
    "\n",
    "This erratum also upgrades the OpenJDK package to IcedTea7 2.3.9. Refer to\n",
    "the NEWS file, linked to in the References, for further information.\n",
    "\n",
    "All users of java-1.7.0-openjdk are advised to upgrade to these updated\n",
    "packages, which resolve these issues. All running instances of OpenJDK Java\n",
    "must be restarted for the update to take effect.\n",
    "\n",
    "'''\n",
    "\n",
    "results = run_prompts(comments)\n",
    "\n",
    "for res in results:\n",
    "    print('Q: {}'.format(res['Q']))\n",
    "    print('A: {}'.format(res['A']))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
